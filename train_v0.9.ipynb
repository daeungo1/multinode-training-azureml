{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Node Training with Hugging Face accelerate and AzureML\n",
        "\n",
        "Reference: https://nateraw.com/posts/multinode_training_accelerate_azureml.html\n",
        "\n",
        "This notebook shows a basic example of multi-node distributed training.\n",
        "\n",
        "[Note] Please use `Python 3.10 - SDK v2 (azureml_py310_sdkv2)` conda environment.\n",
        "\n",
        "## Step 1 - Load config file\n",
        "\n",
        "---\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import time\n",
        "import json\n",
        "import ipykernel\n",
        "    \n",
        "def check_kernel():\n",
        "    kernel_id = ipykernel.connect.get_connection_file()\n",
        "\n",
        "    with open(kernel_id, 'r') as f:\n",
        "        data = json.load(f)  \n",
        "\n",
        "    if data[\"kernel_name\"] == \"\":\n",
        "        print(\"Select kernel first!\")\n",
        "    else:\n",
        "        print(f\"Kernel: {data['kernel_name']}\")\n",
        "\n",
        "check_kernel()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nKernel: python310-sdkv2\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1741584805015
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "from logger import logger\n",
        "from datetime import datetime\n",
        "snapshot_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "with open('config.yml') as f:\n",
        "    d = yaml.load(f, Loader=yaml.FullLoader)\n",
        "    \n",
        "AZURE_SUBSCRIPTION_ID = d['config']['AZURE_SUBSCRIPTION_ID']\n",
        "AZURE_RESOURCE_GROUP = d['config']['AZURE_RESOURCE_GROUP']\n",
        "AZURE_WORKSPACE = d['config']['AZURE_WORKSPACE']\n",
        "AZURE_DATA_NAME = d['config']['AZURE_DATA_NAME']    \n",
        "USE_LOWPRIORITY_VM = d['config']['USE_LOWPRIORITY_VM']\n",
        "\n",
        "use_builtin_env = d['train']['use_builtin_env']  \n",
        "azure_env_name = d['train']['azure_env_name']  \n",
        "azure_compute_cluster_name = d['train']['azure_compute_cluster_name']\n",
        "azure_compute_cluster_size = d['train']['azure_compute_cluster_size']\n",
        "num_training_nodes = d['train']['num_training_nodes']\n",
        "experiment_name = d['train']['experiment_name']    \n",
        "    \n",
        "logger.info(\"===== 1. Azure ML Training Info =====\")\n",
        "\n",
        "logger.info(f\"--- Global Config\")\n",
        "logger.info(f\"AZURE_SUBSCRIPTION_ID={AZURE_SUBSCRIPTION_ID}\")\n",
        "logger.info(f\"AZURE_RESOURCE_GROUP={AZURE_RESOURCE_GROUP}\")\n",
        "logger.info(f\"AZURE_WORKSPACE={AZURE_WORKSPACE}\")\n",
        "logger.info(f\"AZURE_DATA_NAME={AZURE_DATA_NAME}\")\n",
        "logger.info(f\"USE_LOWPRIORITY_VM={USE_LOWPRIORITY_VM}\")\n",
        "\n",
        "logger.info(f\"--- Train Config\")\n",
        "logger.info(f\"use_builtin_env={use_builtin_env}\")\n",
        "logger.info(f\"azure_env_name={azure_env_name}\")\n",
        "logger.info(f\"azure_compute_cluster_name={azure_compute_cluster_name}\")\n",
        "logger.info(f\"azure_compute_cluster_size={azure_compute_cluster_size}\")\n",
        "logger.info(f\"num_training_nodes={num_training_nodes}\")\n",
        "logger.info(f\"experiment_name={experiment_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2025-03-10 05:33:24,966 - logger - INFO - ===== 1. Azure ML Training Info =====\n2025-03-10 05:33:24,974 - logger - INFO - --- Global Config\n2025-03-10 05:33:24,979 - logger - INFO - AZURE_SUBSCRIPTION_ID=59282147-4e06-47ed-bb04-cd383dd85c09\n2025-03-10 05:33:24,985 - logger - INFO - AZURE_RESOURCE_GROUP=rg-az02-rnd-gpu-aks\n2025-03-10 05:33:24,989 - logger - INFO - AZURE_WORKSPACE=ml-az02-rnd-gpu-aks\n2025-03-10 05:33:24,995 - logger - INFO - AZURE_DATA_NAME=<YOUR-DATA>\n2025-03-10 05:33:24,999 - logger - INFO - USE_LOWPRIORITY_VM=False\n2025-03-10 05:33:25,011 - logger - INFO - --- Train Config\n2025-03-10 05:33:25,016 - logger - INFO - use_builtin_env=True\n2025-03-10 05:33:25,022 - logger - INFO - azure_env_name=aml-accelerate\n2025-03-10 05:33:25,022 - logger - INFO - azure_compute_cluster_name=aks-test\n2025-03-10 05:33:25,023 - logger - INFO - azure_compute_cluster_size=Standard_ND96isr_H100_v5\n2025-03-10 05:33:25,023 - logger - INFO - num_training_nodes=2\n2025-03-10 05:33:25,024 - logger - INFO - experiment_name=accelerate-cv-multinode-example\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1741584805197
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure workspace details\n",
        "\n",
        "To connect to a workspace, we need identifying parameters - a subscription, a resource group, and a workspace name. We will use these details in the MLClient from azure.ai.ml to get a handle on the Azure Machine Learning workspace we need. We will use the default Azure authentication for this hands-on.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import time\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient, Input\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import load_component\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml.entities import Data, Environment, BuildContext\n",
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml import Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.core.exceptions import ResourceNotFoundError, ResourceExistsError\n",
        "\n",
        "logger.info(f\"===== 2. Training preparation =====\")\n",
        "logger.info(f\"Calling DefaultAzureCredential.\")\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = None\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    ml_client = MLClient(credential, AZURE_SUBSCRIPTION_ID, AZURE_RESOURCE_GROUP, AZURE_WORKSPACE)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2025-03-10 05:33:25,265 - logger - INFO - ===== 2. Training preparation =====\n2025-03-10 05:33:25,266 - logger - INFO - Calling DefaultAzureCredential.\nFound the config file in: /config.json\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1741584805433
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Get workspace info\n",
        " ws=ml_client.workspaces.get(name=AZURE_WORKSPACE)\n",
        " print(ws.container_registry)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.ContainerRegistry/registries/craz02rndgpuaks\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1741584806299
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Create Compute Targets\n",
        "\n",
        "---\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "def get_or_create_compute_target(ml_client, compute_cluster_name, compute_cluster_size, \n",
        "                                 num_training_nodes=1,\n",
        "                                 use_lowpriority_vm=False, update=False):\n",
        "\n",
        "    try:\n",
        "        compute = ml_client.compute.get(compute_cluster_name)\n",
        "        print(\"The compute cluster already exists! Reusing it for the current run\")\n",
        "    except Exception as ex:\n",
        "        print(\n",
        "            f\"Looks like the compute cluster doesn't exist. Creating a new one with compute size {compute_cluster_size}!\"\n",
        "        )\n",
        "        try:\n",
        "            logger.info(\"Attempt #1 - Trying to create a dedicated compute\")\n",
        "            tier = 'LowPriority' if use_lowpriority_vm else 'Dedicated'\n",
        "            compute = AmlCompute(\n",
        "                name=compute_cluster_name,\n",
        "                size=compute_cluster_size,\n",
        "                tier=tier,\n",
        "                max_instances=num_training_nodes,  # For multi node training set this to an integer value more than 1\n",
        "            )\n",
        "            ml_client.compute.begin_create_or_update(compute).wait()\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "    return compute"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1741584806521
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_compute_cluster_name = \"cpu-cluster\"\n",
        "cpu_compute_cluster_size = \"Standard_E4ds_v4\"\n",
        "gpu_compute_cluster_name = azure_compute_cluster_name\n",
        "gpu_compute_cluster_size = azure_compute_cluster_size\n",
        "\n",
        "def get_num_gpus(gpu_compute_cluster_size):\n",
        "    num_gpu_dict = {\n",
        "        \"Standard_NC24ads_A100_v4\": 1,\n",
        "        \"Standard_NC48ads_A100_v4\": 2,\n",
        "        \"Standard_NC96ads_A100_v4\": 4,\n",
        "        \"Standard_NC40ads_H100_v5\": 1,\n",
        "        \"Standard_NC80adis_H100_v5\": 2,\n",
        "        \"Standard_ND96isr_H100_v5\": 8,\n",
        "    }\n",
        "    return num_gpu_dict[gpu_compute_cluster_size]\n",
        "\n",
        "num_gpus_per_node = get_num_gpus(gpu_compute_cluster_size)\n",
        "\n",
        "cpu_compute = get_or_create_compute_target(\n",
        "    ml_client, cpu_compute_cluster_name, \n",
        "    cpu_compute_cluster_size, num_training_nodes=1, update=False\n",
        ")\n",
        "\n",
        "gpu_compute = get_or_create_compute_target(\n",
        "    ml_client, gpu_compute_cluster_name, \n",
        "    gpu_compute_cluster_size, num_training_nodes=num_training_nodes, update=False\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The compute cluster already exists! Reusing it for the current run\nThe compute cluster already exists! Reusing it for the current run\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1741584807493
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Upload Data to AzureML\n",
        "\n",
        "---\n",
        "\n",
        "So, let’s get some data into AzureML! To do that, we’ll create a data-prep-step that:\n",
        "\n",
        "-   downloads compressed data from a URL,\n",
        "-   extracts it to a new location in AzureML workspace’s storage\n",
        "    Once we do this, we’ll be able to mount this data to our training run later. 💾\n",
        "\n",
        "We start off by creating a `./src` directory where all of our code will live. AzureML uploads all the files within this source directory, so we want to keep it clean.\n",
        "\n",
        "We’ll also define an experiment name, so all the jobs we run here are grouped together.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "src_dir = './src'\n",
        "Path(src_dir).mkdir(exist_ok=True, parents=True)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1741584808742
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Data Upload Script\n",
        "\n",
        "Here’s the data upload script. It simply takes in a path (to a `.tar.gz` file) and extracts it to `output_folder`.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/read_write_data.py\n",
        "import argparse\n",
        "import os\n",
        "import tarfile\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input_data\", type=str)\n",
        "parser.add_argument(\"--output_folder\", type=str)\n",
        "args = parser.parse_args()\n",
        "\n",
        "file = tarfile.open(args.input_data)\n",
        "output_path = os.path.join(args.output_folder)\n",
        "file.extractall(output_path)\n",
        "file.close()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/read_write_data.py\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Data Upload Job\n",
        "\n",
        "Now that we have some code to run, we can define the job. The below basically defines:\n",
        "\n",
        "-   Inputs: The inputs to our script. In our case it’s a `tar.gz` file stored at a URL. This will be downloaded when the job runs. We provide it to our script we wrote above via the `--input_data` flag.\n",
        "-   Outputs: The path where we will save the outputs in our workspace’s data store. We pass this to `--output_folder` in our script.\n",
        "    Environment: We use one of AzureML’s curated environments, which will result in the job starting faster. Later, for the training job, we’ll define a custom environment.\n",
        "-   Compute: We tell the job to run on our cpu-cluster.\n",
        "    Any inputs/outputs you define can be referenced via `${{inputs.<name>}}` and `${{outputs.<name>}}` in the command, so the values are passed along to the script.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "aml_sub = AZURE_SUBSCRIPTION_ID\n",
        "aml_rsg = AZURE_RESOURCE_GROUP\n",
        "aml_ws_name = AZURE_WORKSPACE"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1741584811200
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input in this case is a URL that will be downloaded\n",
        "inputs = {\n",
        "    \"pets_zip\": Input(\n",
        "        type=AssetTypes.URI_FILE,\n",
        "        path=\"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\",\n",
        "    ),\n",
        "}\n",
        "\n",
        "# Define output data. The resulting path will be used in run.py\n",
        "outputs = {\n",
        "    \"pets\": Output(\n",
        "        type=AssetTypes.URI_FOLDER,\n",
        "        path=f\"azureml://subscriptions/{aml_sub}/resourcegroups/{aml_rsg}/workspaces/{aml_ws_name}/datastores/workspaceblobstore/paths/pets\",\n",
        "    )\n",
        "}\n",
        "\n",
        "env = Environment(\n",
        "    image='mcr.microsoft.com/azureml/curated/sklearn-1.5:21',\n",
        "    name=\"aks-test-env\",\n",
        "    description=\"Environment created from a Docker image.\",\n",
        ")\n",
        "\n",
        "# Define our job\n",
        "job = command(\n",
        "    code=src_dir,\n",
        "    command=\"python read_write_data.py --input_data ${{inputs.pets_zip}} --output_folder ${{outputs.pets}}\",\n",
        "    inputs=inputs,\n",
        "    outputs=outputs,\n",
        "    environment=env,\n",
        "    compute=cpu_compute_cluster_name,\n",
        "    experiment_name=experiment_name,\n",
        "    display_name='data-prep-step'\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1741585644979
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Data Upload Job\n",
        "\n",
        "If everything goes smoothly, the below should launch the `data-prep` job, and spit out a link for you to watch it run.\n",
        "\n",
        "You only really need to run this job once, and then can reference it as many times as you like in the training step we are going to define in the next section.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# submit the command\n",
        "returned_job = ml_client.jobs.create_or_update(job)\n",
        "returned_job"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nWarning: the provided asset name 'aks-test-env' will not be used for anonymous registration\nWarning: the provided asset name 'aks-test-env' will not be used for anonymous registration\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "Command({'parameters': {}, 'init': False, 'name': 'gifted_queen_6bvlpql332', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'cpu-cluster', 'ContentSnapshotId': 'c07b47df-fa83-4eec-934d-b18f01846a80'}, 'print_as_yaml': False, 'id': '/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.MachineLearningServices/workspaces/ml-az02-rnd-gpu-aks/jobs/gifted_queen_6bvlpql332', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci-test/code/multinode-training-azureml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f2841c7bfd0>, 'serialize': <msrest.serialization.Serializer object at 0x7f2841ca4e80>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'data-prep-step', 'experiment_name': 'accelerate-cv-multinode-example', 'compute': 'cpu-cluster', 'services': {'Tracking': {'endpoint': 'azureml://koreacentral.api.azureml.ms/mlflow/v1.0/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.MachineLearningServices/workspaces/ml-az02-rnd-gpu-aks?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/gifted_queen_6bvlpql332?wsid=/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks&tid=e6c9ec09-8430-4a99-bf15-242bc089b409', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'pets_zip': {'type': 'uri_file', 'path': 'https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz', 'mode': 'ro_mount'}}, 'job_outputs': {'pets': {'type': 'uri_folder', 'path': 'azureml://subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks/datastores/workspaceblobstore/paths/pets', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.gifted_queen_6bvlpql332', 'mode': 'rw_mount'}}, 'inputs': {'pets_zip': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f2841ca4f40>}, 'outputs': {'pets': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f2841ca4c70>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f2841ca4c10>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'gifted_queen_6bvlpql332', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci-test/code/multinode-training-azureml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f2841c7bfd0>, 'serialize': <msrest.serialization.Serializer object at 0x7f2841ca5390>, 'command': 'python read_write_data.py --input_data ${{inputs.pets_zip}} --output_folder ${{outputs.pets}}', 'code': '/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.MachineLearningServices/workspaces/ml-az02-rnd-gpu-aks/codes/abf69b06-c9a4-4543-be66-bacaf30d60e8/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.MachineLearningServices/workspaces/ml-az02-rnd-gpu-aks/environments/aks-test-env/versions/1', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'data-prep-step', 'is_deterministic': True, 'inputs': {'pets_zip': {'type': 'uri_file', 'path': 'https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz', 'mode': 'ro_mount'}}, 'outputs': {'pets': {'type': 'uri_folder', 'path': 'azureml://subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks/datastores/workspaceblobstore/paths/pets', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.gifted_queen_6bvlpql332', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://koreacentral.api.azureml.ms/mlflow/v1.0/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.MachineLearningServices/workspaces/ml-az02-rnd-gpu-aks?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/gifted_queen_6bvlpql332?wsid=/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks&tid=e6c9ec09-8430-4a99-bf15-242bc089b409', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f2841c7bfd0>}, 'instance_id': 'ed501a38-b0b7-4572-95ec-dcbd86ba6e40', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'aks-test-env:1', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>accelerate-cv-multinode-example</td><td>gifted_queen_6bvlpql332</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/gifted_queen_6bvlpql332?wsid=/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks&amp;tid=e6c9ec09-8430-4a99-bf15-242bc089b409\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1741585656436
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Train\n",
        "\n",
        "---\n",
        "\n",
        "Ok, we have some data! 🙏\n",
        "\n",
        "Let’s see how we can set up multi-node/multi-gpu training with accelerate.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Training Environment\n",
        "\n",
        "For the training job, we’ll define a custom training environment, as our dependencies aren’t included in the curated environments offered by AzureML. We try to pin most of these to very specific versions so the environment won’t break in the future/if we share it with others.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def get_or_create_environment_asset(ml_client, env_name, base_image, conda_yml=\"cloud/conda.yml\", update=False):\n",
        "    \n",
        "    try:\n",
        "        latest_env_version = max([int(e.version) for e in ml_client.environments.list(name=env_name)])\n",
        "        if update:\n",
        "            raise ResourceExistsError('Found Environment asset, but will update the Environment.')\n",
        "        else:\n",
        "            env_asset = ml_client.environments.get(name=env_name, version=latest_env_version)\n",
        "            logger.info(f\"Found Environment asset: {env_name}. Will not create again\")\n",
        "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
        "        print(f\"Exception: {e}\")        \n",
        "        env_docker_image = Environment(\n",
        "            image=base_image,\n",
        "            conda_file=conda_yml,\n",
        "            name=env_name,\n",
        "            description=\"Environment created for llm fine-tuning.\",\n",
        "        )\n",
        "        env_asset = ml_client.environments.create_or_update(env_docker_image)\n",
        "        logger.info(f\"Created/Updated Environment asset: {env_name}\")\n",
        "        \n",
        "    return env_asset\n",
        "\n",
        "def get_or_create_docker_environment_asset(ml_client, env_name, docker_dir, update=False):\n",
        "    \n",
        "    try:\n",
        "        latest_env_version = max([int(e.version) for e in ml_client.environments.list(name=env_name)])\n",
        "        if update:\n",
        "            raise ResourceExistsError('Found Environment asset, but will update the Environment.')\n",
        "        else:\n",
        "            env_asset = ml_client.environments.get(name=env_name, version=latest_env_version)\n",
        "            logger.info(f\"Found Environment asset: {env_name}. Will not create again\")\n",
        "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
        "        logger.info(f\"Exception: {e}\")\n",
        "        env_docker_image = Environment(\n",
        "            build=BuildContext(path=docker_dir),\n",
        "            name=env_name,\n",
        "            description=\"Environment created from a Docker context.\",\n",
        "        )\n",
        "        env_asset = ml_client.environments.create_or_update(env_docker_image)\n",
        "        logger.info(f\"Created Environment asset: {env_name}\")\n",
        "    \n",
        "    return env_asset\n",
        "\n",
        "def get_or_create_data_asset(ml_client, data_name, data_local_dir, update=False):\n",
        "    \n",
        "    try:\n",
        "        latest_data_version = max([int(d.version) for d in ml_client.data.list(name=data_name)])\n",
        "        if update:\n",
        "            raise ResourceExistsError('Found Data asset, but will update the Data.')            \n",
        "        else:\n",
        "            data_asset = ml_client.data.get(name=data_name, version=latest_data_version)\n",
        "            logger.info(f\"Found Data asset: {data_name}. Will not create again\")\n",
        "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
        "        data = Data(\n",
        "            path=data_local_dir,\n",
        "            type=AssetTypes.URI_FOLDER,\n",
        "            description=f\"{data_name} for fine tuning\",\n",
        "            tags={\"FineTuningType\": \"Instruction\", \"Language\": \"En\"},\n",
        "            name=data_name\n",
        "        )\n",
        "        data_asset = ml_client.data.create_or_update(data)\n",
        "        logger.info(f\"Created/Updated Data asset: {data_name}\")\n",
        "        \n",
        "    return data_asset"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1741586492845
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use the conda environment file we just wrote to specify additional dependencies on top of the curated `openmpi3.1.2-ubuntu18.04` docker image from AzureML.\n",
        "\n",
        "For more information on creating environments in AzureML SDK v2, check out the docs.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/train_environment.yml\n",
        "name: aml-video-accelerate\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.10\n",
        "  - pip=24.0\n",
        "  - pip:\n",
        "    - pyarrow==18.0.0\n",
        "    - timm==1.0.11\n",
        "    - setfit==1.1.0\n",
        "    - fire==0.7.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/train_environment.yml\n"
        }
      ],
      "execution_count": 56,
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base_image = \"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.2-cuda12.1:19\"\n",
        "# env = get_or_create_environment_asset(ml_client, azure_env_name, base_image, conda_yml=f\"{src_dir}/train_environment.yml\", update=True)"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1741588618286
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Training Script\n",
        "\n",
        "For our training script, we’re going to use the [complete_cv_example.py](https://github.com/huggingface/accelerate/blob/main/examples/complete_cv_example.py) script from the official [accelerate examples](https://github.com/huggingface/accelerate/tree/main/examples)\n",
        "on GitHub.\n"
      ],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -O {src_dir}/train.py -nc https://raw.githubusercontent.com/huggingface/accelerate/main/examples/complete_cv_example.py"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "File ‘./src/train.py’ already there; not retrieving.\r\n"
        }
      ],
      "execution_count": 58,
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/requirements.txt\n",
        "timm\n",
        "setfit\n",
        "fire"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/requirements.txt\n"
        }
      ],
      "execution_count": 59,
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Training Job\n",
        "\n",
        "The moment of truth! Let’s see if we can train an image classifier using multiple GPUs across multiple nodes on AzureML 🤞\n",
        "\n",
        "Here, we’ll define a job called `train-step` where we define:\n",
        "\n",
        "-   An input, `pets`, which points to the data store path where we stored our processed data earlier.\n",
        "-   Our training command, providing the following flags:\n",
        "    -   `--data_dir:` supplying the input reference path\n",
        "    -   `--with_tracking`: To make sure we save logs\n",
        "    -   `--checkpointing_steps epoch`: To make sure we are saving checkpoints every epoch\n",
        "    -   `--output_dir ./outputs:` Save to the `./outputs` directory, which is a special directory in AzureML meant for saving any artifacts from training.\n",
        "-   Our `training_environment` we defined above.\n",
        "-   The `distribution` as `PyTorch`, specifying `process_count_per_instance`, which is how many GPUs there are per node. (in our case, 2).\n",
        "\n",
        "For more information on how Multi-Node GPU training works on AzureML, you can refer to the [docs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-distributed-gpu?view=azureml-api-2).\n",
        "\n",
        "The `command` allows user to configure the following key aspects.\n",
        "\n",
        "-   `inputs` - This is the dictionary of inputs using name value pairs to the command.\n",
        "    -   `type` - The type of input. This can be a `uri_file` or `uri_folder`. The default is `uri_folder`.\n",
        "    -   `path` - The path to the file or folder. These can be local or remote files or folders. For remote files - http/https, wasb are supported.\n",
        "        -   Azure ML `data`/`dataset` or `datastore` are of type `uri_folder`. To use `data`/`dataset` as input, you can use registered dataset in the workspace using the format '<data_name>:<version>'. For e.g Input(type='uri_folder', path='my_dataset:1')\n",
        "    -   `mode` - Mode of how the data should be delivered to the compute target. Allowed values are `ro_mount`, `rw_mount` and `download`. Default is `ro_mount`\n",
        "-   `code` - This is the path where the code to run the command is located\n",
        "-   `compute` - The compute on which the command will run. You can run it on the local machine by using `local` for the compute.\n",
        "-   `command` - This is the command that needs to be run\n",
        "    in the `command` using the `${{inputs.<input_name>}}` expression. To use files or folders as inputs, we can use the `Input` class. The `Input` class supports three parameters:\n",
        "-   `environment` - This is the environment needed for the command to run. Curated (built-in) or custom environments from the workspace can be used.\n",
        "-   `instance_count` - Number of nodes. Default is 1.\n",
        "-   `distribution` - Distribution configuration for distributed training scenarios. Azure Machine Learning supports PyTorch, TensorFlow, and MPI-based distributed.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "str_command = \"\"\n",
        "\n",
        "if use_builtin_env:\n",
        "    str_env = \"azureml://registries/azureml/environments/tensorflow-2.16-cuda12/versions/6\"  # Use Curated (built-in) Environment asset\n",
        "    str_command += \"pip install -r requirements.txt && \"\n",
        "else:\n",
        "    str_env = f\"{azure_env_name}@latest\" # Use Custom Environment asset\n",
        "    \n",
        "str_command += \"python train.py --data_dir ${{inputs.pets}} --with_tracking --checkpointing_steps epoch --output_dir ./outputs\""
      ],
      "outputs": [],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1741588621804
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(str_env)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml://registries/azureml/environments/tensorflow-2.16-cuda12/versions/6\n"
        }
      ],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1741588622120
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define inputs, which in our case is the path from upload_cats_and_dogs.py\n",
        "inputs = dict(\n",
        "    pets=Input(\n",
        "        type=AssetTypes.URI_FOLDER,\n",
        "        path=f\"azureml://subscriptions/{aml_sub}/resourcegroups/{aml_rsg}/workspaces/{aml_ws_name}/datastores/workspaceblobstore/paths/pets/images\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Define the job!\n",
        "job = command(\n",
        "    code=src_dir,\n",
        "    inputs=inputs,\n",
        "    command=str_command,\n",
        "    environment=str_env,\n",
        "    compute=gpu_compute_cluster_name,\n",
        "    instance_count=num_training_nodes,  # In this, only 2 node cluster was created.\n",
        "    distribution={\n",
        "        \"type\": \"PyTorch\",\n",
        "        # set process count to the number of gpus per node\n",
        "        # In our case (using Standard_NC12) we have 2 GPUs per node.\n",
        "        \"process_count_per_instance\": num_gpus_per_node,\n",
        "    },\n",
        "    # environment_variables={\n",
        "    #     \"MLFLOW_TRACKING_URI\": \"\"  # no use mlflow\n",
        "    # },    \n",
        "    experiment_name=experiment_name,\n",
        "    display_name='train-step'\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1741588622785
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Training Job\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_job = ml_client.jobs.create_or_update(job)\n",
        "display(train_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading src (0.03 MBs):   0%|          | 0/29292 [00:00<?, ?it/s]\r\u001b[32mUploading src (0.03 MBs): 100%|██████████| 29292/29292 [00:00<00:00, 928376.98it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Command({'parameters': {}, 'init': False, 'name': 'helpful_river_3j3jpdw446', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'aksv2train', '_azureml.ClusterName': 'aks-test', 'ContentSnapshotId': '6397ad16-3ef0-4414-bc36-d7bb188de4b0'}, 'print_as_yaml': False, 'id': '/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.MachineLearningServices/workspaces/ml-az02-rnd-gpu-aks/jobs/helpful_river_3j3jpdw446', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci-test/code/multinode-training-azureml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f284182eda0>, 'serialize': <msrest.serialization.Serializer object at 0x7f28416482b0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'train-step', 'experiment_name': 'accelerate-cv-multinode-example', 'compute': 'aks-test', 'services': {'Tracking': {'endpoint': 'azureml://koreacentral.api.azureml.ms/mlflow/v1.0/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.MachineLearningServices/workspaces/ml-az02-rnd-gpu-aks?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/helpful_river_3j3jpdw446?wsid=/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks&tid=e6c9ec09-8430-4a99-bf15-242bc089b409', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'pets': {'type': 'uri_folder', 'path': 'azureml://subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks/datastores/workspaceblobstore/paths/pets/images', 'mode': 'ro_mount'}}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.helpful_river_3j3jpdw446', 'mode': 'rw_mount'}}, 'inputs': {'pets': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f2841648610>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f28416487f0>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'helpful_river_3j3jpdw446', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci-test/code/multinode-training-azureml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f284182eda0>, 'serialize': <msrest.serialization.Serializer object at 0x7f2841648580>, 'command': 'pip install -r requirements.txt && python train.py --data_dir ${{inputs.pets}} --with_tracking --checkpointing_steps epoch --output_dir ./outputs', 'code': '/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.MachineLearningServices/workspaces/ml-az02-rnd-gpu-aks/codes/c20f24fc-cb2d-42c8-ae3b-92207c6631db/versions/1', 'environment_variables': {}, 'environment': 'azureml://registries/azureml/environments/tensorflow-2.16-cuda12/versions/6', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f2841ca4070>, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'train-step', 'is_deterministic': True, 'inputs': {'pets': {'type': 'uri_folder', 'path': 'azureml://subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks/datastores/workspaceblobstore/paths/pets/images', 'mode': 'ro_mount'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.helpful_river_3j3jpdw446', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://koreacentral.api.azureml.ms/mlflow/v1.0/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourceGroups/rg-az02-rnd-gpu-aks/providers/Microsoft.MachineLearningServices/workspaces/ml-az02-rnd-gpu-aks?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/helpful_river_3j3jpdw446?wsid=/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks&tid=e6c9ec09-8430-4a99-bf15-242bc089b409', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f284182eda0>}, 'instance_id': 'a6f5b027-2059-403b-89eb-7f71e781b141', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f2841ca4070>, 'environment_variables': {}, 'environment': 'azureml://registries/azureml/environments/tensorflow-2.16-cuda12/versions/6', 'resources': {'instance_count': 2, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>accelerate-cv-multinode-example</td><td>helpful_river_3j3jpdw446</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/helpful_river_3j3jpdw446?wsid=/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks&amp;tid=e6c9ec09-8430-4a99-bf15-242bc089b409\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1741588628403
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(\"\"\"Started training job. Now a dedicated Compute Cluster for training is provisioned and the environment\n",
        "required for training is automatically set up from Environment.\n",
        "\n",
        "If you have set up a new custom Environment, it will take approximately 20 minutes or more to set up the Environment before provisioning the training cluster.\n",
        "\"\"\")\n",
        "ml_client.jobs.stream(train_job.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: helpful_river_3j3jpdw446\nWeb View: https://ml.azure.com/runs/helpful_river_3j3jpdw446?wsid=/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks\n\nExecution Summary\n=================\nRunId: helpful_river_3j3jpdw446\nWeb View: https://ml.azure.com/runs/helpful_river_3j3jpdw446?wsid=/subscriptions/59282147-4e06-47ed-bb04-cd383dd85c09/resourcegroups/rg-az02-rnd-gpu-aks/workspaces/ml-az02-rnd-gpu-aks\n\nWarnings:\n{\"Compliant\":\"System unhealthy with error: Component Executor unhealthy with err Service 'Executor' returned invalid response: status: Unknown, message: \\\"transport error\\\", details: [], metadata: MetadataMap { headers: {} }\"}\n{\"Compliant\":\"Component Executor unhealthy with err Service 'Executor' returned invalid response: status: Unknown, message: \\\"transport error\\\", details: [], metadata: MetadataMap { headers: {} }\"}\n{\"Compliant\":\"Service 'Executor' returned invalid response: status: Unknown\nAML Kubernetes Compute job failed.\n-1200: ContainerDockerOOMKilled matched: {\"containers\":[{\"name\":\"bfee3d23201f47dcb33abb8b3d77be91-execution-wrapper\",\"reason\":\"OOMKilled\",\"message\":\"\\\"koreacentral\\\" experiment_id=\\\"9945d799-4d7a-443b-ac9f-a878ff8ad99a\\\" experiment_name=\\\"accelerate-cv-multinode-example\\\" root_run_id=\\\"helpful_river_3j3jpdw446\\\" run_id=\\\"helpful_river_3j3jpdw446\\\" attempt_id=\\\"0\\\" node_id=\\\"ccf8d30a-f331-4961-9fdc-e45b00952aa1\\\" node_rank=\\\"1\\\" correlation_id=\\\"helpful_river_3j\n\n"
        },
        {
          "output_type": "error",
          "ename": "JobException",
          "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"ServiceError\",\n        \"message\": \"{\\\"Compliant\\\":\\\"System unhealthy with error: Component Executor unhealthy with err Service 'Executor' returned invalid response: status: Unknown, message: \\\\\\\"transport error\\\\\\\", details: [], metadata: MetadataMap { headers: {} }\\\"}\\n{\\\"Compliant\\\":\\\"Component Executor unhealthy with err Service 'Executor' returned invalid response: status: Unknown, message: \\\\\\\"transport error\\\\\\\", details: [], metadata: MetadataMap { headers: {} }\\\"}\\n{\\\"Compliant\\\":\\\"Service 'Executor' returned invalid response: status: Unknown, message: \\\\\\\"transport error\\\\\\\", details: [], metadata: MetadataMap { headers: {} }\\\"}\\n{\\\"Compliant\\\":\\\"Service 'Executor' returned invalid response: status: Unknown, message: \\\\\\\"transport error\\\\\\\", details: [], metadata: MetadataMap { headers: {} }\\\"}\\n{\\n  \\\"code\\\": \\\"LifecycleError\\\",\\n  \\\"target\\\": \\\"\\\",\\n  \\\"category\\\": \\\"SystemError\\\",\\n  \\\"error_details\\\": [],\\n  \\\"inner_error\\\": {\\n    \\\"code\\\": \\\"SystemUnhealthyError\\\",\\n    \\\"target\\\": \\\"\\\",\\n    \\\"category\\\": \\\"SystemError\\\",\\n    \\\"error_details\\\": [],\\n    \\\"inner_error\\\": {\\n      \\\"code\\\": \\\"HealthError\\\",\\n      \\\"target\\\": \\\"\\\",\\n      \\\"category\\\": \\\"SystemError\\\",\\n      \\\"error_details\\\": [],\\n      \\\"inner_error\\\": {\\n        \\\"code\\\": \\\"InvalidResponse\\\",\\n        \\\"target\\\": \\\"\\\",\\n        \\\"category\\\": \\\"SystemError\\\",\\n        \\\"error_details\\\": []\\n      }\\n    }\\n  }\\n}\",\n        \"message_parameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n} ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJobException\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[64], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mStarted training job. Now a dedicated Compute Cluster for training is provisioned and the environment\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mrequired for training is automatically set up from Environment.\u001b[39m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mIf you have set up a new custom Environment, it will take approximately 20 minutes or more to set up the Environment before provisioning the training cluster.\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:289\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    287\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    288\u001b[0m         ):\n\u001b[0;32m--> 289\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:818\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[38;5;241m=\u001b[39mjob_object\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 818\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_ops_helper.py:334\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    332\u001b[0m         file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m    335\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)),\n\u001b[1;32m    336\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m    337\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised on failed job.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    339\u001b[0m         )\n\u001b[1;32m    341\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    342\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n",
            "\u001b[0;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"ServiceError\",\n        \"message\": \"{\\\"Compliant\\\":\\\"System unhealthy with error: Component Executor unhealthy with err Service 'Executor' returned invalid response: status: Unknown, message: \\\\\\\"transport error\\\\\\\", details: [], metadata: MetadataMap { headers: {} }\\\"}\\n{\\\"Compliant\\\":\\\"Component Executor unhealthy with err Service 'Executor' returned invalid response: status: Unknown, message: \\\\\\\"transport error\\\\\\\", details: [], metadata: MetadataMap { headers: {} }\\\"}\\n{\\\"Compliant\\\":\\\"Service 'Executor' returned invalid response: status: Unknown, message: \\\\\\\"transport error\\\\\\\", details: [], metadata: MetadataMap { headers: {} }\\\"}\\n{\\\"Compliant\\\":\\\"Service 'Executor' returned invalid response: status: Unknown, message: \\\\\\\"transport error\\\\\\\", details: [], metadata: MetadataMap { headers: {} }\\\"}\\n{\\n  \\\"code\\\": \\\"LifecycleError\\\",\\n  \\\"target\\\": \\\"\\\",\\n  \\\"category\\\": \\\"SystemError\\\",\\n  \\\"error_details\\\": [],\\n  \\\"inner_error\\\": {\\n    \\\"code\\\": \\\"SystemUnhealthyError\\\",\\n    \\\"target\\\": \\\"\\\",\\n    \\\"category\\\": \\\"SystemError\\\",\\n    \\\"error_details\\\": [],\\n    \\\"inner_error\\\": {\\n      \\\"code\\\": \\\"HealthError\\\",\\n      \\\"target\\\": \\\"\\\",\\n      \\\"category\\\": \\\"SystemError\\\",\\n      \\\"error_details\\\": [],\\n      \\\"inner_error\\\": {\\n        \\\"code\\\": \\\"InvalidResponse\\\",\\n        \\\"target\\\": \\\"\\\",\\n        \\\"category\\\": \\\"SystemError\\\",\\n        \\\"error_details\\\": []\\n      }\\n    }\\n  }\\n}\",\n        \"message_parameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n} "
          ]
        }
      ],
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1741588922953
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the `trained_model` output is available\n",
        "job_name = train_job.name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1741586683541
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%store job_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "## Step 5 (Optional) - Create model asset and get fine-tuned LLM to local folder\n",
        "\n",
        "---\n",
        "\n",
        "### Create model asset\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def get_or_create_model_asset(ml_client, model_name, job_name, model_dir=\"outputs\", model_type=\"custom_model\", update=False):\n",
        "    \n",
        "    try:\n",
        "        latest_model_version = max([int(m.version) for m in ml_client.models.list(name=model_name)])\n",
        "        if update:\n",
        "            raise ResourceExistsError('Found Model asset, but will update the Model.')\n",
        "        else:\n",
        "            model_asset = ml_client.models.get(name=model_name, version=latest_model_version)\n",
        "            logger.info(f\"Found Model asset: {model_name}. Will not create again\")\n",
        "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
        "        logger.info(f\"Exception: {e}\")        \n",
        "        model_path = f\"azureml://jobs/{job_name}/outputs/artifacts/paths/{model_dir}/\"    \n",
        "        run_model = Model(\n",
        "            name=model_name,        \n",
        "            path=model_path,\n",
        "            description=\"Model created from run.\",\n",
        "            type=model_type # mlflow_model, custom_model, triton_model\n",
        "        )\n",
        "        model_asset = ml_client.models.create_or_update(run_model)\n",
        "        logger.info(f\"Created Model asset: {model_name}\")\n",
        "\n",
        "    return model_asset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "azure_model_name = d['serve']['azure_model_name']\n",
        "model_dir = d['train']['model_dir']\n",
        "\n",
        "model = get_or_create_model_asset(ml_client, azure_model_name, job_name, model_dir, model_type=\"custom_model\", update=False)\n",
        "\n",
        "logger.info(\"===== 4. (Optional) Create model asset and get fine-tuned LLM to local folder =====\")\n",
        "logger.info(f\"azure_model_name={azure_model_name}\")\n",
        "logger.info(f\"model_dir={model_dir}\")\n",
        "logger.info(f\"model={model}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the model (this is optional)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# local_model_dir = \"./artifact_downloads\"\n",
        "# os.makedirs(local_model_dir, exist_ok=True)\n",
        "# ml_client.models.download(name=azure_model_name, download_path=local_model_dir, version=model.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}